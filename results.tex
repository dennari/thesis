
\subsection{Analytical comparison of methods}

Both the direct method of section~\ref{sec:grad} and the EM algorithm of section~\ref{sec:EM_SSM}
have their strengths and weaknesses. Neither of them can be said to eclipse the other in an absolute sense.
In this section we will go through some features of the said algorithms found in the literature.
Then a more detailed analysis will be performed on two essential aspects of any estimation algorithm:
the convergence properties, i.e. when should one expect the algorithm to find a local maximum and
the computational requirements of the algorithms.

\textcite{Cappe2005} contains a list of arguments in favor of either of the methods. The following list includes
those and additional points with comments:
\begin{description}
  \item[Direct]\hfill
\begin{itemize}
  \item\emph{No smoother needed} The log-likelihood, or an approximation to it, can be evaluated
  with forward-filtering
  \item\emph{No M-step}. There is no need to figure out model-dependent maximization
  formulas even in nonlinear models 
  \item\emph{Faster convergence}. Advanced gradient-based optimization
  methods can reach convergence speeds that are close to quadratic
\end{itemize}
  \item[EM]\hfill
  \begin{itemize}
  \item \emph{Simple to implement}. This argument is often put forward in favor of the EM
 algorithm. However in practice when using the gradient-based method one would use any one of
the off-the-self nonlinear optimizers and not re-implement one. Thus which one is easier to implement
boils down to gradient computation. If the model is linear or linear-in-the-parameters the EM
algorithm doesn't need any gradient information.
  \item\emph{Parameter constraints}. In \textcite{Cappe2005} it is argued that
since the M-step maximization equations are so simple, including parameter constraints
are easier in the EM algorithm. This again depends on if the model is linear or linear-in-the-parameters.
  \item\emph{Parameterization independent}. This again depends on if one has to use gradient-based
 optimization in the M-step. If not, then the EM algorithm is parameterization independent. In the gradient-based
 method the gradient and the Hessian, and so the convergence, are affected by the parameterization.
\end{itemize} 
\end{description}

\clearpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%% BALLISTIC OBJECT %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Endoathmospheric flight of a ballistic projectile}\label{sec:ballistic}
Let us consider a situation where a ballistic projectile is launched
from the ground into the air. We assume that the situation is governed by Newtonian
mechanics and that the projectile experiences a constant known gravitational
force. In addition a velocity and altitude dependent drag force plays
a considerable role in the trajectory of the projectile \parencite{ristic2004beyond}. 
The drag force is caused by the air which might have a nonzero velocity with respect to the ground,
depending on the wind conditions.
 
We obtain a sequence of range measurements with a radar,
so that our data consists of the noisy two dimensional locations 
of the object as measured at time points $\brac{t_k}_{k=1}^T$.
We assume a constant interval $\tau$ between the time points.

Since the wind conditions are unknown, we supposet there is not
enough information for explicitly modeling the drag force. 
This is compensated by introducing
uncertainty into the dynamics with an additive stochastic process.
With these considerations, the system can be cast into a linear-Gaussian
SSM. 

% Newton's laws are specified in continous time,  where
% the dynamics can now be written as
% \begin{align}
% 	\dod{\x(t)}{t} &= \v{F}\x(t) + \gv{\beta}(t)
% 	\label{eq:ct_linear}
% \end{align}
% with
% \begin{align}
% 	\x(t) &= \bm{x(t) & \dot{x}(t) & \ddot{x}(t) & y(t) & \dot{y}(t) & \ddot{y}(t)}^\tr\\
% 	\v{F}&=\bm{
% 	&&1&&&\\
% 	&&&1&&\\
% 	&&&&1&\\
% 	&&&&&1\\
% 	&&&&&\\
% 	&&&&&\\
% 	}
% 	\label{tablelabel}
% \end{align}

To discretize the dynamics, we will apply a simple integration scheme where 
$\x(t)=\x(t_k)$ when $t\in\brak{t_k,t_{k+1}}$ \parencite{bar2004estimation}.
In this model, the state will contain the position and
its first derivative, i.e the velocity. We will model the acceleration as a white noise
process, allowing some flexibility with respect to effects caused by additional forces not explicitly
included in the model.

The system will be modeled in two dimensional Cartesian coordinates so that $d_x=4$, i.e
two components for position and two for velocity. The state at time $k$ is then
\begin{align}
	\xk &=
	\bm{x^{(1)}_k & \dot{x}^{(1)}_k  
	  & x^{(2)}_k & \dot{x}^{(2)}_k }^\tr
	\label{eq:ballistic2D_state}
\end{align}
where
\begin{align}
	x_k &= x(t_k)   & \text{and} && \dot{x}_k &= \eval{\dod{x(t)}{t}}_{t=t_k}.
\end{align}
The powers in Equation~\eqref{eq:ballistic2D_state} denote the Cartesian components.
The corresponding measurement without the additive noise is
\begin{align}
	\yk-\v{r}_k &= \bm{x^{(1)}_k & x^{(2)}_k }^\tr.
	\label{eq:ballistic2D_measurementsl}
\end{align}

\begin{figure}[htb]%
    \centering%
    \includegraphics{img/ballistic_trajectory}%
	\caption{%
	A simulation of the trajectory
	of the projectile in model~\eqref{eq:ballistic_model}.
   	The measurements are denoted with crosses. %
   	}
	\label{fig:ballistic2D_simulation}
 \end{figure}

The linear-Gaussian SSM can now be written as
\begin{align}
	\begin{aligned}
	\x_k &= \v{A}\xkk+\v{u}+\v{L}\v{v}_{k-1}, & \v{v}_{k-1} &\sim \N{\v{0}}{\bm{\sigma_1^{2} & \\ & \sigma_2^{2}}}\\
	\yk &= \v{H}\xk+\v{r}_k, & 					\v{r}_k 	&\sim \N{\v{0}}{\sigma_r^2\v{I}},
	\end{aligned}\label{eq:ballistic_model}
\end{align}
where
\begin{align*}
	\v{A}&=\bm{
	1& \tau & 	& 		\\
	 &	1	& 	&		\\
	 &		& 1	& \tau 	\\
	 &		&	& 1
	}\\
	\v{u} &= \bm{ & g_1 &  & g_2}^\tr\\
	\v{L} &= \bm{\tau & 1 & &\\ & & \tau & 1}^\tr\\
	\v{H} &= \bm{1 & & &\\ & & 1 &}
\end{align*}
If we wish to replace $\v{L}v_{k-1}$ with the more familiar $\v{q}_{k-1}$,
then $\v{q}_{k-1}\sim \N{\v{0}}{\v{Q}}$ where
\begin{align}
	\v{Q} &= \v{L}\bm{\sigma_1^{2} & \\ & \sigma_2^{2}}\v{L}^\tr 
	%\sigma_1^2\bm{\frac{\tau^4}{4} & \frac{\tau^3}{2} &
	%\frac{\tau^2}{2}\\
	%\frac{\tau^3}{2} & \tau^2 & \tau\\ \frac{\tau^2}{2} & \tau & 1}
	\label{eq:ballistic_Q}
\end{align}
Additionally, the initial state $\x_0$ is assumed to be normally
distributed with $\N{\gv\mu_0}{\v{I}}$, where
\begin{align}
	\gv\mu_0 &= \bm{0 & \cos(\alpha_0)v_0 & 0 & \sin(\alpha_0)v_0}^\tr\\
	%\gv\Sigma_0 &= \mathrm{diag}\big(\bm{0 & 10^2 & 0 & 0 & 10^2 & 0}\big).
	\label{eq:ballistic_prior}
\end{align}
In other words, we assume the covariance matrix fully known
and specify further that the initial position and velocity
are deterministic and known.

Next we will focus on simulating measurements from the model and then estimating
the model parameters. The parameters of the initial distribution are chosen as
$\alpha_0 = \ang{50}$ and $v_0 = \SI{40}{m/s}$ and the initial state $\x_0$ is then
drawn from $\N{\gv\mu_0}{\gv\Sigma_0}$. The amount of drift in the gravitational force 
is controlled by the parameters $\sigma_1$ and $\sigma_2$.
These determine the standard deviations in the horizontal and vertical
components of the force per a single time step of duration $\tau$.
We will set 
\begin{align}
	\sigma_1&=\tau\,\si{m/s^2}\\
	\sigma_2&=\SI{0}{m/s^2}.
\end{align} 
%
Figure~\ref{fig:ballistic2D_simulation} presents  a simulated dataset, 
which is drawn from the two dimensional ballistic model with the aforementioned parameter
values.



Let us then proceed to maximum likelihood static parameter estimation. The training
data will be the simulated data, so that the true parameter values are the ones presented
earlier. In this case the most interesting parameter is probably the initial velocity,
i.e the angle $\alpha_0\in(0,\sfrac{\pi}{2})$ and the magnitude $v_0$, since it determines
the trajectory to a high degree.

 
Let us collect the parameters in the set $\Th=\brac{\sigma_1,\sigma_2,\sigma_r}$.

\parencite{ristic2004beyond,Ratna2008,Lindsten2010}
 %
% To demonstrate filtering and smoothing, the filtering distributions were
% computed with the Kalman filter of section~\ref{sec:kalman_filter} and the smoothing distributions with
% the RTS smoother of section~\ref{sec:rts_smoother}. The results of the simulation are presented in
% Figure~\ref{fig:ballistic}. The uncertainty in the filtering distributions is noticeably larger
% when compared to the smoothing distributions, since the smoothing distributions
% include the information of the ``future'' measurements in addition to the past and the current ones.
% \todo{analyze the figure a bit more} 

% \begin{figure}[htb]%
%     \centering%
%     \begin{subfigure}[t]{0.5\textwidth}%
%     	\centering%
%     	\caption{EM}\label{fig:ballistic_lh_em}%
%     	\includegraphics[width=\textwidth]{img/ballistic_lh_em}%
%     \end{subfigure}%
%     \begin{subfigure}[t]{0.5\textwidth}%
%     	\centering%
%     	\caption{BFGS}\label{fig:ballistic_lh_bf}%
% 		\includegraphics[width=\textwidth]{img/ballistic_lh_bf}%
%     \end{subfigure}%
% 	\caption{Convergence of the likelihood with EM and BFGS}
% 	\label{fig:ballistic_lh}
%  \end{figure}
 
 \begin{figure}[htb]%
    \centering%
    \makebox[\textwidth]{%
    \begin{subfigure}[t]{0.5\textwidth+0.4in}%
    	\caption{EM}
    	\includegraphics{img/ballistic_lh_em}%
    	%\caption{Convergence of the likelihood with EM}%
		%\label{fig:ballistic_lh_em}%
    \end{subfigure}%
    \begin{subfigure}[t]{0.5\textwidth+0.4in}%
		\caption{BFGS}
		\includegraphics{img/ballistic_lh_bf}%
    	%\caption{Convergence of the likelihood with BFGS}%
		%\label{fig:ballistic_lh_bf}%
    \end{subfigure}}\\%
    \makebox[\textwidth]{%
    \begin{subfigure}[t]{0.5\textwidth+0.4in}%
    	\includegraphics{img/ballistic_em_uy}%
    	%\caption{Convergence of the likelihood with EM}%
		%\label{fig:ballistic_lh_em}%
    \end{subfigure}%
    \begin{subfigure}[t]{0.5\textwidth+0.4in}%
		\includegraphics{img/ballistic_bf_uy}%
    	%\caption{Convergence of the likelihood with BFGS}%
		%\label{fig:ballistic_lh_bf}%
    \end{subfigure}}\\%
    \makebox[\textwidth]{%
    \begin{subfigure}[t]{0.5\textwidth+0.4in}%
    	\includegraphics{img/ballistic_em_ux}%
    	%\caption{Convergence of the likelihood with EM}%
		%\label{fig:ballistic_lh_em}%
    \end{subfigure}%
    \begin{subfigure}[t]{0.5\textwidth+0.4in}%
		\includegraphics{img/ballistic_bf_ux}%
    	%\caption{Convergence of the likelihood with BFGS}%
		%\label{fig:ballistic_lh_bf}%
    \end{subfigure}}\\%
    \makebox[\textwidth]{%
	\begin{subfigure}[b]{0.5\textwidth+0.4in}%
    	\includegraphics{img/ballistic_em_r}%
    	%\caption{Convergence of the likelihood with EM}%
		%\label{fig:ballistic_lh_em}%
    \end{subfigure}%
    \begin{subfigure}[b]{0.5\textwidth+0.4in}%
		\includegraphics{img/ballistic_bf_r}%
    	%\caption{Convergence of the likelihood with BFGS}%
		%\label{fig:ballistic_lh_bf}%
    \end{subfigure}}%
    \caption{Convergence of the likelihood with EM and BFGS}\label{fig:ballistic_est}
 \end{figure}
 

\clearpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%% HEART %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Electrocardiograph analysis}

The second demonstration is concerned with a nonlinear model for
electrocardiograph (ECG) data, a short sequence of which is presented
in Figure~\ref{fig:ecg_data}. A realistic model for this data 
should take into account the quasi-periodic nature of ECG data,
i.e. the frequency must be allowed to vary with time.
Following the ideas in \textcite{Sarkka2012}, one possibility
is to write the model as a superposition of noisy resonators
with time-varying frequencies.

In continous time we can write a stochastic differential equation
for the $n$:th harmonic as
\begin{align}
	 \ddot{c}_n(t)&= -\omega(t)^2c_n(t)+\varepsilon_n(t),
	 %\dod[2]{c_n(t)}{t}
	\label{eq:noisy_resonator}
\end{align}
where $c_n(t)$ is the displacement from equilibrium at time $t$.
The angular velocity $\omega$ is related to the frequency $f$
by $\omega(t)=2\pi f(t)$ and  $\varepsilon_n(t)$ is additive
white noise with spectral density $q_n$. For constant frequency and
zero spectral density, the solution of Equation~\eqref{eq:noisy_resonator}
is well known to be $c_n(t)=\exp(i n \omega t+\phi_n)$, where $\phi_n\in\field{C}$ depends on 
the initial conditions.

Writing Equation~\eqref{eq:noisy_resonator} as a vector valued first order differential equation
and dividing the noise and the signal derivative by $n\omega(t)$, we get
\begin{align}
	\dod{}{t}\bm{c_n(t) \\ \widehat{\dot{c}}_n(t)} &= \bm{0 & \omega(t)^2 \\ -\omega(t) 0}\bm{c_n(t) \\
	\widehat{\dot{c}}_n(t)}+\bm{0\\1}
	\widehat{\varepsilon}_n(t).
	\label{eq:noisy_resonator_vec}
\end{align}
As explained in \textcite{Sarkka2012}, even if Equation~\eqref{eq:noisy_resonator_vec} is not an exact
representation of Equation~\eqref{eq:noisy_resonator}, its discretized version has more appealing
properties than that of the exact version. Furthermore, the process noise can account for some
modeling errors. 

Discretizing Equation~\eqref{eq:noisy_resonator_vec} at equispaced points $\brac{t_k}_{k=1}^T$
with interval $\tau$ and assuming $\omega(t)=\omega(t_k)\equiv \omega_k$ when $t\in\brak{t_k,t_{k+1}}$,
we get the following dynamic model for displacement $x^{(n)}$:
\begin{align}
	\bm{x_k^{(n)} \\ \dot{x}_k^{(n)}} &\sim 
	\N{\bm{\cos(n\omega_k) & \sin(n\omega_k) \\% 
	   -\sin(n\omega_k) & \cos(n\omega_k)}
	   \bm{x_{k-1}^{(n)} \\ \dot{x}_{k-1}^{(n)}}}
	  {\bm{0 & 0 \\ 0 & \tau q_x}}.
	\label{eq:dynamic_displacement}
\end{align}
We assume that $\omega_k$ is part of the state and assume its dynamics obey the previously introduced first order
random walk model (with $a=1$):
\begin{align}
	\omega_k \sim \N{\omega_{k-1}}{\tau q_\omega}.
	\label{eq:omega_ar}
\end{align}
The joint dynamic model of $m$ harmonics and $\omega_k$ is then
\begin{align}
	\underbrace{\bm{\omega_k \\ x_k^{(1)} \\ \dot{x}_k^{(1)} \\ \vdots \\  x_k^{(m)} \\ \dot{x}_k^{(m)} }}_{\xk} 
	=
	%\N{
	\underbrace{\bm{1&&&&&\\
		& \cos(\omega_k) & \sin(\omega_k) &&&\\% 
	    &-\sin(\omega_k) & \cos(\omega_k) &&&\\
	    &				  &					& \ddots & &\\
	 &&&& \cos(m\omega_k) & \sin(m\omega_k) \\% 
	 &&&&-\sin(m\omega_k) & \cos(m\omega_k) \\
	}
	\bm{\omega_k \\ x_{k-1}^{(1)} \\ \dot{x}_{k-1}^{(1)} \\ \vdots \\  x_{k-1}^{(m)} \\ \dot{x}_{k-1}^{(m)} }}_{\ffi}
	%}{
	%\v{Q}
	%},
	+ \v{q}_{k-1}
	\label{eq:harmonic_joint}
\end{align}
where
\begin{align}
	\q_{k-1}\sim\N{\v{0}}{\tau\bm{q_\omega&&&&&\\ & 0 &&&& \\ && q_x &&& \\ &&& \ddots && \\ &&&& 0 & \\ &&&&& q_x}}
	\label{tablelabel}
\end{align}


 
 \begin{figure}[htb]%
    \centering%
    \includegraphics{img/harmonic_trajectory}%
	\caption{%
	A short sequence of the ECG data. %
   	}
	\label{fig:ecg_data}
 \end{figure}
 
 \begin{figure}[htb]%
    \centering%
    \makebox[\textwidth]{%
    \begin{subfigure}[t]{0.5\textwidth+0.4in}%
    	\caption{EM}
    	\includegraphics{img/harmonic_em_lh}%
    	%\caption{Convergence of the likelihood with EM}%
		%\label{fig:harmonic_lh_em}%
    \end{subfigure}%
    \begin{subfigure}[t]{0.5\textwidth+0.4in}%
		\caption{BFGS}
		\includegraphics{img/harmonic_bf_lh}%
    	%\caption{Convergence of the likelihood with BFGS}%
		%\label{fig:harmonic_lh_bf}%
    \end{subfigure}}\\%
    \makebox[\textwidth]{%
    \begin{subfigure}[t]{0.5\textwidth+0.4in}%
    	\includegraphics{img/harmonic_em_lqw}%
    	%\caption{Convergence of the likelihood with EM}%
		%\label{fig:harmonic_lh_em}%
    \end{subfigure}%
    \begin{subfigure}[t]{0.5\textwidth+0.4in}%
		\includegraphics{img/harmonic_bf_lqw}%
    	%\caption{Convergence of the likelihood with BFGS}%
		%\label{fig:harmonic_lh_bf}%
    \end{subfigure}}\\%
    \makebox[\textwidth]{%
    \begin{subfigure}[t]{0.5\textwidth+0.4in}%
    	\includegraphics{img/harmonic_em_lqx}%
    	%\caption{Convergence of the likelihood with EM}%
		%\label{fig:harmonic_lh_em}%
    \end{subfigure}%
    \begin{subfigure}[t]{0.5\textwidth+0.4in}%
		\includegraphics{img/harmonic_bf_lqx}%
    	%\caption{Convergence of the likelihood with BFGS}%
		%\label{fig:harmonic_lh_bf}%
    \end{subfigure}}%\\%
%     \makebox[\textwidth]{%
% 	\begin{subfigure}[b]{0.5\textwidth+0.4in}%
%     	\includegraphics{img/harmonic_em_lr}%
%     	%\caption{Convergence of the likelihood with EM}%
% 		%\label{fig:harmonic_lh_em}%
%     \end{subfigure}%
%     \begin{subfigure}[b]{0.5\textwidth+0.4in}%
% 		\includegraphics{img/harmonic_bf_lr}%
%     	%\caption{Convergence of the likelihood with BFGS}%
% 		%\label{fig:harmonic_lh_bf}%
%     \end{subfigure}}%
    \caption{Convergence of the likelihood and estimates with EM and BFGS}\label{fig:harmonic_est}
 \end{figure}
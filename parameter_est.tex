

Something should be said about the difference
of states and parameters.
This need becomes obvious when noting that the SSM of equation~\eqref{eq:ssm_too_general}
could be reformulated by concatenating $\Th$ as part of the state. In this
way a separate parameter estimation problem would not exist. However, the 
separation becomes important after assuming the parameters static. Instead of 
approximating a separate ``parameter" distribution for every
timestep, we then know that by separating the static part into
$\Th$ we can do with a single parameter distribution for the whole model. 


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Bayesian Estimation of Parameters}%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
We now shift the focus on estimating the parameter $\Th$, which was assumed
given in the case of state estimation. In the Bayesian sense the complete 
answer would be the \emph{joint} distribution of the states and the parameters given the data. 
Since $\Pdf{\X,\Th}{\Y}=\Pdf{\X}{\Th,\Y}\Pdf{\Th}{\Y}$, we can clearly 
divide the solution to the state estimation part $\Pdf{\X}{\Th,\Y}$,
considered in the previous section, 
and the parameter estimation part $\Pdf{\Th}{\Y}$. Knowing these
factors is enough to simulate the joint distribution \parencite{gelman2004}. 

By Bayes' rule we have
\begin{align}
	\Pdf{\Th}{\Y}&=\frac{\Pdf{\Y}{\Th}\Pdf{\Th}}{\Pdf{\Y}}\\
	&=\frac{\Pdf{\Y}{\Th}\Pdf{\Th}}{\defint{\Theta}{}{\Pdf{\Y}{\Th}\Pdf{\Th}}{\Th}}.
	\label{eq:param_post}
\end{align}
By defining the SSM in equation~\eqref{eq:ssm_general}, we have
implicitely defined the ``complete-data'' likelihood $\Pdf{\X,\Y}{\Th}$
(see Equation~\eqref{eq:complete_data_likelihood}).
Computing \eqref{eq:param_post} requires the marginal likelihood
$\Pdf{\Y}{\Th}=\defint{\mathcal{X}}{}{\Pdf{\X,\Y}{\Th}}{\X}$ which
was shown to be computed exactly by the Kalman filter in the linear-Gaussian case
or which can be approximated by a Gaussian filter in the nonlinear-Gaussian case.



A much easier problem is finding a suitable \emph{point estimate} $\hat{\gv{\theta}}$.
This effectively means that we don't need to worry about the normalizing
term $\Pdf{\Y}$, since it's constant with respect to the parameters. 
A point estimate that maximizes the posterior distribution
is called a \emph{maximum a posteriori} (MAP) estimate. 
Since the logarithm is a strictly monotonic function, maximizing a function
is the same as maximizing its logarithm. Thus the MAP estimate $\Th^*$ is given by 
\begin{align}
	\Th_{\text{MAP}} &= \argmax_{\Th}\brak[\big]{\underbrace{\log \Pdf{\Y}{\gv{\theta}}}_{\Pdf[\ell]{\Th}} + \log\Pdf{\gv{\theta}}}
	\label{eq:MAP}
\end{align}

In the case of a flat (constant and thus improper)
prior distribution, $\Pdf{\Th}$, the MAP estimate reduces to the
\emph{maximum likelihood} (ML) estimate
\begin{align}
	\Th_{\text{ML}} &= \argmax_{\Th}\brak*\lLH
	\label{eq:ML}
\end{align}
Going further we we will only be concerned with finding the ML estimate, but it should
be remembered that both of the methods we consider can be extended
to the estimation of the MAP estimate in a straightforward fashion.
\todo{Explain MAP in both cases}


\subsubsection{Maximum a posteriori and maximum likelihood}

\subsubsection{Ascent methods}

Both of the parameter estimation methods we are going
discuss, the expectation maximization algorithm and
the instances of gradient based nonlinear programming dealt with in the
next chapter, belong to the class of \emph{iterative ascent methods} \parencite{luenberger2008}.
They are iterative since they produce a series of estimates, where
always the next estimate is based on the previous estimates and
the value of the objective function is increased with every new estimate.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Gradient based nonlinear optimization of parameters}\label{sec:grad}%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{parameter_est_gradient}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Expectation maximization (EM)}%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{parameter_est_em}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Theoretical considerations}%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{parameter_est_theoretical}



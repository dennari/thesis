%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Bayesian Estimation of Parameters}%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In the Bayesian sense the complete answer to the parameter estimation
problem is the marginal posterior probability of the parameters
given the measurements, which is given by Bayes' rule as
\begin{align}
	\Pdf{\gv{\theta}}{\Y}&=\frac{\Pdf{\Y}{\gv{\theta}}\Pdf{\gv{\theta}}}{\Pdf{\Y}}.
	\label{eq:param_post}
\end{align}

Computing the posterior distribution of the parameters is usually intractable \todo{Explain more about bayesian
methods. This should include mentions about SMC. Then explain the motivations for point estimates: starting point
for MCMC, complexity\ldots}.
A much easier problem is finding a suitable \emph{point estimate} $\hat{\gv{\theta}}$.
This effectively means that we don't need to worry about the normalizing
term $\Pdf{\Y}$, since it's constant with respect to the parameters. 
A point estimate that maximizes the posterior distribution
is called a \emph{maximum a posteriori} (MAP) estimate. 
Since the logarithm is a strictly monotonic function, maximizing a function
is the same as maximizing its logarithm. Thus the MAP estimate $\Th^*$ is given by 
\begin{align}
	\Th_{\text{MAP}} &= \argmax_{\Th}\brak[\big]{\underbrace{\log \Pdf{\Y}{\gv{\theta}}}_{\Pdf[\ell]{\Th}} + \log\Pdf{\gv{\theta}}}
	\label{eq:MAP}
\end{align}

In the case of a flat (constant and thus improper)
prior distribution, $\Pdf{\Th}$, the MAP estimate reduces to the
\emph{maximum likelihood} (ML) estimate
\begin{align}
	\Th_{\text{ML}} &= \argmax_{\Th}\brak*\lLH
	\label{eq:ML}
\end{align}
Going further we we will only be concerned with finding the ML estimate, but it should
be remembered that both of the methods we consider can be extended
to the estimation of the MAP estimate in a straightforward fashion.
\todo{Explain MAP in both cases}


\subsubsection{Maximum a posteriori and maximum likelihood}

\subsubsection{Ascent methods}

Both of the parameter estimation methods we are going
discuss, the expectation maximization algorithm and
the instances of gradient based nonlinear programming dealt with in the
next chapter, belong to the class of \emph{iterative ascent methods} \parencite{luenberger2008}.
They are iterative since they produce a series of estimates, where
always the next estimate is based on the previous estimates and
the value of the objective function is increased with every new estimate.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Gradient based nonlinear optimization of parameters}\label{sec:grad}%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{parameter_est_gradient}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Expectation maximization (EM)}%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{parameter_est_em}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Theoretical considerations}%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{parameter_est_theoretical}



\subsection{Linear-Gaussian State Space Models}

Since linear mappings can be described by matrices, stationary linear-Gaussian SSMs 
are described by the subset of SSMs of the form \eqref{eq:ssm_general} where  
\begin{align}
	\v{f}_{\Th}\left(\x_{k-1}\right)&=\v{A}\x_{k-1}\\
	\v{h}_{\Th}\left(\xk\right)&=\v{H}\xk
\end{align}
\todo{Explain something about linear-Gaussian SSMs}

\subsubsection{Kalman filter}

The recursions are as follows \parencite{Kalman1960,jazwinski2007stochastic}:
\todo{Elaborate on the Kalman filter}
\begin{subequations}
\label{eq:Kalman_filter}
\begin{description}
\addtolength{\leftskip}{1cm}
\item[Predict:]
\begin{align}
	\v{m}_{k|k-1}&=\v{A}\v{m}_{k-1|k-1}\\
	\v{P}_{k|k-1}&=\v{A}\v{P}_{k-1|k-1}\v{A}^\tr+\v{Q}
\end{align}
\item[Update:]
\begin{align}
	\v{v}_k&=\v{y}_k-\v{H}\v{m}_{k|k-1}\\
	\v{S}_k&=\v{H}\v{P}_{k|k-1}\v{H}^\tr+\v{R}\\
	\v{K}_k&=\v{P}_{k|k-1}\v{H}^\tr\v{S}_{k}^{-1}\\
	\v{m}_{k|k}&=\v{m}_{k|k-1}+\v{K}_k\v{v}_k\\
	\v{P}_{k|k}&=\v{P}_{k|k-1}-\v{K}_k\v{S}_k\v{K}_{k}^\tr
\end{align}
\end{description}
\end{subequations}
This includes the sufficient statistics for the $T$
joint distributions 
\begin{align}
	\Pdf{\v{x}_k,\v{y}_k}{\v{y}_{1:k-1},\gv{\theta}}
	&=\N[
	\begin{bmatrix}
		\v{x}_k\\\v{y}_{k}
	\end{bmatrix}
	]{
	\begin{bmatrix}
		\v{m}_{k|k-1}\\
		\v{H}\v{m}_{k|k-1}
	\end{bmatrix}
	,
	\begin{bmatrix}
		\v{P}_{k|k-1} & \v{P}_{k|k-1}\v{H}^\tr\\
		\v{H}\v{P}_{k|k-1}^\tr & \v{S}_k  
	\end{bmatrix}
	}
	\label{eq:joint_per_kalmanstep}
\end{align}

\subsubsection{Rauch-Tung-Striebel Smoother}

The standard Rauch-Tung-Striebel (RTS) smoother gives the statistics $\v{m}_{k|T}$ and $\v{P}_{k|T}$ \parencite{jazwinski2007stochastic,Rauch1965}.
\begin{subequations}
\begin{align}
	\v{J}_k&=\v{P}_{k|k}\v{A}^\tr\v{P}_{k|k+1}^{-1}\\
	\v{m}_{k|T}&=\v{m}_{k|k}+\v{J}_k\left(\v{m}_{k+1|T}-\v{m}_{k+1|k}\right)\\
	\v{P}_{k|T}&=\v{P}_{k|k}+\v{J}_k\left(\v{P}_{k+1|T}-\v{P}_{k+1|k}\right)\v{J}_k^\tr
	%\v{C}_{k|T}&=\v{P}_{k|k}\v{J}_{k-1}^\tr+\v{J}_k\left(\v{C}_{k+1|T}-\v{A}\v{P}_{k|k}\right)\v{J}_{k-1}^\tr \label{eq:rts_cross_timestep_covariance}
\end{align}
\end{subequations}
\begin{align}
\begin{split} 
	\Pdf{\v{x}_k, \v{x}_{k-1}}{\v{Y},\Th}&=
	\N[\bm{\v{x}_k\\\v{x}_{k-1}}]{
	\bm{
		\v{m}_{k|T}\\
		\v{m}_{k-1|T}
	}
	,
	\bm{
		\v{P}_{k|T} & \v{P}_{k|T}\v{J}_k^\tr\\
		\v{J}_k\v{P}_{k|T} & \v{P}_{k-1|T}  
	}
	}
\end{split}
\end{align}

In \parencite{Elliott1999} a new kind of filter is presented that
can compute \eqref{eq:sum_expectations} with only forward recursions. 
\todo{Elaborate on the RTS smoother}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Nonlinear-Gaussian SSMs}%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\label{sec:nonlinear_state}
In the nonlinear case at least one of the mappings $\v{f}_{\Th}$ and $\v{h}_{\Th}$ in
\eqref{eq:ssm_general} is nonlinear. Unfortunately in this case computing the filtering
distributions in closed form becomes intractable and one has to resort to approximations.
Finding good approximations is however extremely valuable since a great many
physically modeled dynamical phenoma could be forumulated as nonlinear-Gaussian SSM.

The types of approximate filtering (and smoothing) solutions can be put into two 
categories: particle filtering (or sequential Monte Carlo), which is asymptotically exact but
computationally demanding and different kinds of deterministic approximation methods that
are analytically inexact but less computationally demanding. We will only focus
on the latter category. \todo{Mention EKF}

\subsubsection{Gaussian filtering and smoothing}

One approach to forming Gaussian approximations is to assume a
Gaussian probability density function with mean and variance that match the
actual ones \parencite{Ito2000,Sarkka2006}. Let 
\begin{align}
	\v{a}&\sim \N{\v{m},\gv{\Sigma}_a} \label{eq:pa}\\
	\v{b}|\v{a}&\sim \N{\v{f}(\v{a}),\gv{\Sigma}_{b|a}} \label{eq:pb_given_a}
\end{align}
then 
\begin{align}
	\label{eq:joint_nongaussian}
	\Pdf{\v{a},\v{b}}&=\N{\v{m},\gv{\Sigma}_a}\N{\v{f}(\v{a}),\gv{\Sigma}_{b|a}}
\end{align}
is only Gaussian if $\v{f}(\v{a})$ is linear. Let the Gaussian approximation
to \eqref{eq:joint_nongaussian} be

\begin{align}
	\label{eq:joint_gaussian_approx}
	\Pdf{\begin{bmatrix}
		\v{a}\\
		\v{b}
	\end{bmatrix}}&\approx
	\N{
	\begin{bmatrix}
		\gv{\mu}_a\\
		\gv{\mu}_b
	\end{bmatrix},
	\begin{bmatrix}
		\gv{\Sigma}_{aa}&\gv{\Sigma}_{ab}\\
		\gv{\Sigma}_{ba}&\gv{\Sigma}_{bb}
	\end{bmatrix}
	}
\end{align}
Then since the marginal distributions of a Gaussian distribution are also
Gaussian, we have to have
\begin{align}
	\gv{\mu}_a&=\v{m}\\
	\gv{\Sigma}_{aa}&=\gv{\Sigma}_{a}\\
	\gv{\mu}_b&=\defint{}{}{\v{b}\,\Pdf{\v{b}}}{\v{b}} \label{eq:mub}\\
	\gv{\Sigma}_{bb}&=\defint{}{}{(\v{b}-\gv{\mu}_b)(\v{b}-\gv{\mu}_b)^\tr\Pdf{\v{b}}}{\v{b}} \label{eq:varb}
\end{align}
Both \eqref{eq:mub} and \eqref{eq:varb} can be written in terms of \eqref{eq:pa} and \eqref{eq:pb_given_a}.
To see this, let us rewrite \eqref{eq:mub} as
\begin{align}
	\gv{\mu}_b&=\defint{}{}{\v{b}\Pdf{\v{b}}}{\v{b}} \nonumber\\
	&=\defint{}{}{\v{b}\left(\defint{}{}{\Pdf{\v{b}}{\v{a}}\Pdf{\v{a}}}{\v{a}}\right)}{\v{b}}\nonumber\\
	&=\defint{}{}{\v{f}(\v{a})\N{\v{m},\gv{\Sigma}_a}}{\v{a}}\label{eq:mean_int}
\end{align}
and \eqref{eq:varb} as
\begin{align}
	\gv{\Sigma}_{bb}&=\defint{}{}{\v{b}\v{b}^\tr\Pdf{\v{b}}}{\v{b}}-\gv{\mu}_b\gv{\mu}_b^\tr \nonumber\\
	%&=\defint{}{}{\defint{}{}{\lbrack(\v{b}-\v{f}(\v{a}))(\v{b}-\v{f}(\v{a}))^\tr+\v{f}(\v{a})\v{f}(\v{a})^\tr\rbrack\Pdf{\v{b}}{\v{a}}}{\v{b}}\Pdf{\v{a}}}{\v{a}}-\gv{\mu}_b\gv{\mu}_b^\tr\\
	\begin{split}
	&=\defint{}{}{\v{f}(\v{a})\v{f}(\v{a})^\tr\Pdf{\v{a}}}{\v{a}}-\gv{\mu}_b\gv{\mu}_b^\tr\\
	&\qquad+\defint{}{}{\lbrack(\v{b}-\v{f}(\v{a}))(\v{b}-\v{f}(\v{a}))^\tr\rbrack\Pdf{\v{b}}{\v{a}}}{\v{a}}{\v{b}}
	\end{split}\nonumber\\
	&=\defint{}{}{(\v{f}(\v{a})-\gv{\mu}_b)(\v{f}(\v{a})-\gv{\mu}_b)^\tr\N{\v{m},\gv{\Sigma}_a}}{\v{a}}+\gv{\Sigma}_{b|a}\label{eq:var_int}.
\end{align}
Finally, the cross-covariance $\gv{\Sigma}_{ab}=\gv{\Sigma}_{ba}^\tr$ similarly reads
\begin{align}
	\gv{\Sigma}_{ab}&=\defint{}{}{(\v{a}-\gv{\mu}_a)(\v{b}-\gv{\mu}_b)^\tr\Pdf{\v{a},\v{b}}}{\v{a}}{\v{b}} \nonumber\\
	&=\defint{}{}{(\v{a}-\gv{\mu}_a)(\v{b}-\gv{\mu}_b)^\tr\Pdf{\v{a}}\Pdf{\v{b}}{\v{a}}}{\v{a}}{\v{b}} \nonumber\\
	&=\defint{}{}{(\v{a}-\gv{\mu}_a)\left(\defint{}{}{\v{b}\Pdf{\v{b}}{\v{a}}}{\v{b}}-\gv{\mu}_b\right)^\tr\Pdf{\v{a}}}{\v{a}} \nonumber\\
	&=\defint{}{}{(\v{a}-\v{m})(\v{f}(\v{a})-\gv{\mu}_b)^\tr\N{\v{m},\gv{\Sigma}_a}}{\v{a}}\label{eq:cross_cov_int}
\end{align}


 
To see how this idea can be used to form a Gaussian
approximation to \eqref{eq:joint_posterior_of_consecutive_states}, let us
rewrite \eqref{eq:joint_posterior_of_consecutive_states} as
\begin{align}
\begin{split}
	\Pdf{\v{x}_{k-1},\v{x}_{k}}{\v{Y}}&=\Pdf{\v{x}_{k-1}}{\v{x}_{k},\v{Y}_{1:k-1}}\Pdf{\v{x}_{k}}{\v{Y}}\\
	&=\frac{\Pdf{\v{x}_{k-1},\v{x}_{k}}{\v{Y}_{1:k-1}}\Pdf{\v{x}_{k}}{\v{Y}}}{\Pdf{\v{x}_{k}}{\v{Y}_{1:k-1}}},
	\label{eq:joint_smooth}
\end{split}
\end{align}
where the dependance on the current estimate of the parameter $\hat{\Th}_j$
is suppressed for clarity. Since the Gaussian approximation to
\eqref{eq:joint_posterior_of_consecutive_states} will be calculated by forward
(filtering) and backward (smoothing) recursions, let us assume that we already
have available the Gaussian approximation

\begin{align}
	%\Pdf{\v{x}_{k}}{\v{Y},\hat{\Th}_j} &\approx \N{\v{m}_{k|T},\v{P}_{k|T}}\\
	\Pdf{\v{x}_{k-1}}{\v{Y}_{1:k-1},\hat{\Th}_j} &\approx \N{\v{m}_{k-1|k-1},\v{P}_{k-1|k-1}}.
	%\Pdf{\v{x}_{k}}{\v{Y}_{1:k-1},\hat{\Th}_j} &\approx \N{\v{m}_{k|k-1},\v{P}_{k|k-1}}.
\end{align}
The Gaussian approximation to 
\begin{align}
\Pdf{\v{x}_{k-1},\v{x}_{k}}{\v{Y}_{1:k-1}}=\N{\v{x}_{k}}{\v{f}(\v{x}_{k-1}),\v{Q}}\Pdf{\v{x}_{k-1}}{\v{Y}_{1:k-1}}
\end{align}
is then given by application of equations \eqref{eq:mean_int}, \eqref{eq:var_int} and \eqref{eq:cross_cov_int} 
\begin{align}
	\begin{split}
	\v{m}_{k|k-1}&=\defint{}{}{\v{f}(\v{x}_{k-1})\N{\v{x}_{k-1}}{\v{m}_{k-1|k-1},\v{P}_{k-1|k-1}}}{\v{x}_{k-1}}\label{eq:prediction_mean_intergral}
	\end{split}\\
	\begin{split}
	\v{P}_{k|k-1}&=\defint{}{}{(\v{f}(\v{x}_{k-1})-\v{m}_{k|k-1})(\v{f}(\v{x}_{k-1})-\v{m}_{k|k-1})^\tr\\
	&\qquad\N{\v{x}_{k-1}}{\v{m}_{k-1|k-1},\v{P}_{k-1|k-1}}}{\v{x}_{k-1}}+\v{Q}\label{eq:prediction_variance_intergral}
	\end{split}\\
	\begin{split}
		\v{C}_{k^-}&=\defint{}{}{(\v{x}_{k-1}-\v{m}_{k-1|k-1})(\v{f}(\v{x}_{k-1})-\v{m}_{k|k-1})^\tr\\
		&\qquad\N{\v{x}_{k-1}}{\v{m}_{k-1|T},\v{P}_{k-1|T}}}{\v{x}_{k-1}}\label{eq:prediction_cov_intergral}
	\end{split}
\end{align}
so that the approximation is
\begin{align}
	\Pdf{\v{x}_{k-1},\v{x}_k}{\v{Y}_{1:k-1},\hat{\Th}_j}&\approx 
	\N{
	\begin{bmatrix}
		\v{m}_{k-1|k-1}\\
		\v{m}_{k|k-1}
	\end{bmatrix},
	\begin{bmatrix}
		\v{P}_{k-1|k-1}&\v{C}_{k^-}\\
		\v{C}_{k^-}^\tr&\v{P}_{k|k-1}
	\end{bmatrix}
	}
	\label{eq:joint_predictive_approximation}
\end{align}
In order to calculate \eqref{eq:prediction_mean_intergral} and \eqref{eq:prediction_variance_intergral}
we also need a Gaussian approximation for the joint distribution of
the current state and measurement given the previous measurements
\begin{align}
\begin{split}
	\Pdf{\v{x}_{k},\v{y}_k}{\v{Y}_{1:k-1}}&=\N{\v{y}_{k}}{\v{h}(\v{x}_{k}),\v{R}}\Pdf{\v{x}_{k}}{\v{Y}_{1:k-1}}\\
	&\approx 
	\N{
	\begin{bmatrix}
		\v{m}_{k|k-1}\\
		\gv{\mu}_{k}
	\end{bmatrix},
	\begin{bmatrix}
		\v{P}_{k|k-1}&\v{C}_{k}\\
		\v{C}_{k}^\tr&\v{S}_{k}
	\end{bmatrix}
	}.
	\label{eq:joint_update_approximation}
\end{split}
\end{align}
Applying equations \eqref{eq:mean_int}, \eqref{eq:var_int} and \eqref{eq:cross_cov_int} again,
we get
\begin{align}
	\gv{\mu}_{k}
	&=\defint{}{}{\v{h}(\v{x}_{k})\N{\v{x}_{k}}{\v{m}_{k|k-1},\v{P}_{k|k-1}}}{\v{x}_{k}}\label{eq:update_mean_intergral}\\
	\v{S}_{k}
	&=\defint{}{}{(\v{h}(\v{x}_{k})-\gv{\mu}_k)(\v{h}(\v{x}_{k})-\gv{\mu}_k)^\tr\N{\v{x}_{k}}{\v{m}_{k|k-1},\v{P}_{k|k-1}}}{\v{x}_{k}}+\v{R} \label{eq:update_variance_intergral}\\
	\v{C}_{k}
	&=\defint{}{}{(\v{x}_{k}-\v{m}_{k|k-1})(\v{h}(\v{x}_{k})-\gv{\mu}_k)^\tr\N{\v{x}_{k}}{\v{m}_{k|k-1},\v{P}_{k|k-1}}}{\v{x}_{k}} \label{eq:update_covariance_intergral}
\end{align}
and by using the well known formula for calculating the conditional distribution of jointly Gaussian variables
we have
\begin{align}
	\v{m}_{k|k}
	&=\v{m}_{k|k-1}+\v{C}_{k}\v{S}_{k}^{-1}\left(\v{y}_k-\gv{\mu}_k\right)\label{eq:update_mean}\\
	\v{P}_{k|k}
	&=\v{P}_{k|k-1}-\v{C}_{k}\v{S}_{k}^{-1}\v{C}_{k}^\tr. \label{eq:update_variance}
\end{align}
Again using the formula for the conditional of jointly Gaussian variables we get
from \eqref{eq:joint_predictive_approximation}
\begin{align}
	\Pdf{\v{x}_{k-1}}{\v{x}_k,\v{Y}_{1:k-1}}&\approx\N{\v{m}_2,\v{P}_2}\\
	\v{G}_{k-1}&=\v{C}_{k^-}\v{P}_{k|k-1}^{-1}\\
	\v{m}_2&=\v{m}_{k-1|k-1}+\v{G}_{k-1}(\v{x}_k-\v{m}_{k|k-1})\\
	\v{P}_2&=\v{P}_{k-1|k-1}-\v{G}_{k-1}\v{P}_{k|k-1}\v{G}_{k-1}^\tr
\end{align}
and then finally we can write the Gaussian approximation to the joint distribution of consecutive states given all the measurements
as
\begin{align}
\begin{split}
	\Pdf{\v{x}_{k-1},\v{x}_{k}}{\v{Y}}&=\Pdf{\v{x}_{k-1}}{\v{x}_{k},\v{Y}_{1:k-1}}\Pdf{\v{x}_{k}}{\v{Y}}\\
	&\approx
	\N{
	\begin{bmatrix}
		\v{m}_{k-1|T}\\
		\v{m}_{k|T}
	\end{bmatrix},
	\begin{bmatrix}
		\v{P}_{k-1|T}&\v{D}_{k}\\
		\v{D}_{k}^\tr&\v{P}_{k|T}
	\end{bmatrix}
	}
\end{split}
\end{align}
where
\begin{align}
	\v{D}_{k}&=\v{G}_{k-1}\v{P}_{k|T}\\
	\v{m}_{k-1|T}&=\v{m}_{k-1|k-1}+\v{G}_{k-1}\left(\v{m}_{k|T}-\v{m}_{k|k-1}\right)\\
	\v{P}_{k-1|T}&=\v{P}_{k-1|k-1}+\v{G}_{k-1}\left(\v{P}_{k|T}-\v{P}_{k|k-1}\right)\v{G}_{k-1}^\tr
\end{align}

\subsubsection{Quadrature and cubature}
\parencite{Arasaratnam2009}
\subsubsection{Gauss-Hermite Kalman Filter and Smoother}
\parencite{Ito2000}
\subsubsection{Unscented Kalman Filter and Smoother}
\parencite{julier1997new,Merwe2004}
\subsubsection{Cubature Kalman Filter and Smoother}
\parencite{Arasaratnam2009,Arasaratnam2011,Jia2012}




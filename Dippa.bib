@article{Dempster1977,
author = {Dempster, AP and Laird, NM},
file = {:Users/dennari/Documents/Papers/Dempster, Laird - 1977 - Maximum likelihood from incomplete data via the {EM} algorithm.pdf:pdf},
journal = {Journal of the Royal Statistical Society.},
number = {1},
pages = {1--38},
title = {Maximum likelihood from incomplete data via the {EM} algorithm},
url = {http://www.jstor.org/stable/10.2307/2984875},
volume = {39},
year = {1977}
}
@phdthesis{Saatci2011,
author = {Saatci, Yunus},
file = {:Users/dennari/Documents/Papers/Saatci - 2011 - Scalable Inference for Structured {Gauss}ian Process Models.pdf:pdf},
school = {University of Cambridge},
title = {Scalable Inference for Structured {Gauss}ian Process Models},
year = {2011}
}
@article{Roweis1999,
author = {Roweis, Sam and Ghahramani, Zoubin},
file = {:Users/dennari/Documents/Papers/Roweis, Ghahramani - 1999 - A Unifying Review of Linear {Gauss}ian Models.pdf:pdf},
journal = {Neural computation},
number = {1995},
pages = {305--345},
title = {A Unifying Review of Linear {Gauss}ian Models},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/089976699300016674},
volume = {345},
year = {1999}
}
@article{Segal1989,
author = {Segal, M and Weinstein, E},
doi = {10.1109/18.30995},
file = {:Users/dennari/Documents/Papers/Segal, Weinstein - 1989 - A new method for evaluating the log-likelihood gradient, the {Hess}ian, and the Fisher information matrix for linear dynamic systems.pdf:pdf},
issn = {0018-9448},
journal = {Information Theory, IEEE Transactions on},
keywords = {Fisher information matrix,{Hess}ian,gradient-based algorithms,identification,information theory,linear dynamic systems,linear systems,log-likelihood gradient,maximum-likelihood identification,mean-square estimation accuracy,optimal {Kalman} smoothing equations,optimisation,parameter estimation,parameter identification,state estimation,stochastic systems},
month = may,
number = {3},
pages = {682--687},
title = {A new method for evaluating the log-likelihood gradient, the {Hessian}, and the {Fisher} information matrix for linear dynamic systems},
volume = {35},
year = {1989}
}
@article{Maeda2007,
author = {Maeda, Shin-ichi and Ishii, Shin},
doi = {10.1109/MLSP.2007.4414326},
file = {:Users/dennari/Documents/Papers/Maeda, Ishii - 2007 - Convergence Analysis of the {EM} Algorithm and Joint Minimization of Free Energy.pdf:pdf},
isbn = {978-1-4244-1565-6},
issn = {1551-2541},
journal = {2007 IEEE Workshop on Machine Learning for Signal Processing},
month = aug,
number = {x},
pages = {318--323},
publisher = {Ieee},
title = {Convergence Analysis of the {EM} Algorithm and Joint Minimization of Free Energy},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4414326},
year = {2007}
}
@article{Wu1983,
abstract = {Two convergence aspects of the {EM} algorithm are studied: (i) does the {EM} algorithm find a local maximum or a stationary value of the (incomplete-data) likelihood function? (ii) does the sequence of parameter estimates generated by {EM} converge? Several convergence results are obtained under conditions that are applicable to many practical situations. Two useful special cases are: (a) if the unobserved complete-data specification can be described by a curved exponential family with compact parameter space, all the limit points of any {EM} sequence are stationary points of the likelihood function; (b) if the likelihood function is unimodal and a certain differentiability condition is satisfied, then any {EM} sequence converges to the unique maximum likelihood estimate. A list of key properties of the algorithm is included.},
author = {Wu, C F Jeff},
file = {:Users/dennari/Documents/Papers/Wu - 1983 - On the Convergence Properties of the {EM} Algorithm.pdf:pdf},
issn = {00905364},
journal = {The Annals of Statistics},
number = {1},
pages = {pp. 95--103},
publisher = {Institute of Mathematical Statistics},
title = {On the Convergence Properties of the {EM} Algorithm},
url = {http://www.jstor.org/stable/2240463},
volume = {11},
year = {1983}
}
@techreport{Sandell1978,
author = {Sandell, Nils Richard and Yared, Khaled Ibrahim},
file = {:Users/dennari/Documents/Papers/Sandell, Yared - 1978 - Maximum likelihood identification of state space models for linear dynamic systems.pdf:pdf},
institution = {Electronic Systems Laboratory, Dept. of Electrical Engineering and Computer Science, Massachusetts Institute of Technology},
number = {ESL-R-814},
pages = {83},
title = {Maximum likelihood identification of state space models for linear dynamic systems},
url = {http://hdl.handle.net/1721.1/1297},
urldate = {2012-07-17},
year = {1978}
}
@article{Shelley2007,
author = {Shelley, K H},
file = {:Users/dennari/Documents/Papers/Shelley - 2007 - Photoplethysmography beyond the calculation of arterial oxygen saturation and heart rate.pdf:pdf},
journal = {Anesthesia \& Analgesia},
number = {6S Suppl},
pages = {S31----S36},
publisher = {IARS},
title = {Photoplethysmography: beyond the calculation of arterial oxygen saturation and heart rate},
volume = {105},
year = {2007}
}
@misc{r2012,
address = {Vienna, Austria},
annote = {\{ISBN\} 3-900051-07-0},
author = {{R Core Team}},
institution = {R Foundation for Statistical Computing},
title = {R},
subtitle = {A Language and Environment for Statistical Computing},
url = {http://www.r-project.org},
urldate = {2012-10-16},
year = {2012}
}
@article{Lange1995,
abstract = {In many problems of maximum likelihood estimation, it is impossible to carry out either the E-step of the {EM} algorithm. The present paper introduces a gradient algorithm that is closely related to the {EM} algorithm. This {EM} gradient algorithm approximately solves the M-step of the {EM} algorithm by one iteration of {Newton}'s method. Since {Newton}'s method converges quickly, the local properties of the {EM} gradient algorithm are almost identical with those of the {EM} algorithm. Any strict local maximum point of the observed likelihood locally attracts the {EM} and {EM} gradient algorithm at the same rate of convergence, and near the maximum point the {EM} gradient algorithm always produces an increase in the likelihood. With proper modification the {EM} gradient algorithm also exhibits global convergence properties that are similar to those of the {EM} algorithm. Our proof of global convergence applies and improves existing theory for the {EM} algorithm. These theoretical points are reinforced by a discussion of three realistic examples illustrating how the {EM} gradient algorithm can succeed where the {EM} algorithm is intractable.},
author = {Lange, Kenneth},
file = {:Users/dennari/Documents/Papers/Lange - 1995 - A Gradient Algorithm Locally Equivalent to the {EM} Algorithm.pdf:pdf},
issn = {00359246},
journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
number = {2},
pages = {pp. 425--437},
publisher = {Blackwell Publishing for the Royal Statistical Society},
title = {A Gradient Algorithm Locally Equivalent to the {EM} Algorithm},
url = {http://www.jstor.org/stable/2345971},
volume = {57},
year = {1995}
}
@book{Bishop2006,
author = {Bishop, C.M.},
file = {:Users/dennari/Documents/Papers/Bishop - 2006 - Pattern recognition and machine learning.pdf:pdf},
isbn = {9780387310732},
publisher = {Springer Verlag},
title = {Pattern recognition and machine learning},
url = {http://www.library.wisc.edu/selectedtocs/bg0137.pdf},
year = {2006}
}
@inproceedings{Salakhutdinov2003,
author = {Salakhutdinov, Ruslan and Roweis, Sam and Ghahramani, Zoubin},
booktitle = {Proc. 19th Conference in Uncertainty in Artificial Intelligence},
file = {:Users/dennari/Documents/Papers/Salakhutdinov, Roweis - 2003 - On the convergence of bound optimization algorithms.pdf:pdf},
title = {On the convergence of bound optimization algorithms},
url = {http://web.mit.edu/~rsalakhu/www/papers/boundopt.pdf},
year = {2003}
}
@article{Schon2011,
author = {Sch\"{o}n, Thomas B and Wills, Adrian and Ninness, Brett},
issn = {0005-1098},
journal = {Automatica},
keywords = {Dynamic systems,Expectation maximisation algorithm,{Monte Carlo} method,Nonlinear models,Particle methods,Smoothing filters,System identification},
month = jan,
number = {1},
pages = {39--49},
title = {System identification of nonlinear state-space models},
url = {http://www.sciencedirect.com/science/article/pii/S0005109810004279},
volume = {47},
year = {2011}
}
@article{Lindsten2010,
author = {Lindsten, Fredrik},
file = {:Users/dennari/Documents/Papers/Lindsten - 2010 - Identification of mixed linearnonlinear state-space models.pdf:pdf},
journal = {and Control (CDC), 2010 49th IEEE},
title = {Identification of mixed linear/nonlinear state-space models},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=5717191},
year = {2010}
}
@article{Wu2006,
author = {Wu, Yuanxin and Hu, D and Wu, Meiping and Hu, Xiaoping},
doi = {10.1109/TSP.2006.875389},
file = {:Users/dennari/Documents/Papers/Wu et al. - 2006 - A Numerical-Integration Perspective on {Gauss}ian Filters.pdf:pdf},
issn = {1053-587X},
journal = {Signal Processing, IEEE Transactions on},
keywords = {{Bayes} methods,{Bayes}ian inference approximation,{Gauss}ian filters,{Gauss}ian posterior probability density,{Gauss}ian processes,filtering theory,integration,multiple statistical integrations,numerical stability,numerical-integration perspective,stability factor},
number = {8},
pages = {2910--2921},
title = {A Numerical-Integration Perspective on {Gauss}ian Filters},
volume = {54},
year = {2006}
}
@book{ristic2004beyond,
author = {Ristic, B and Arulampalam, S and Gordon, N},
isbn = {9781580536318},
publisher = {Artech House},
series = {Artech House Radar Library},
title = {Beyond the {Kalman} Filter: Particle Filters for Tracking Applications},
url = {http://books.google.fi/books?id=zABIY--qk2AC},
year = {2004}
}
@article{Ionides2011,
archivePrefix = {arXiv},
arxivId = {arXiv:0902.0347v1},
author = {Ionides, EL and Bhadra, Anindya and Atchad\'{e}, Y and King, Aaron},
eprint = {arXiv:0902.0347v1},
file = {:Users/dennari/Documents/Papers/Ionides et al. - 2011 - Iterated filtering(2).pdf:pdf},
journal = {The Annals of Statistics},
pages = {1--27},
title = {Iterated filtering},
url = {http://projecteuclid.org/euclid.aos/1311600283},
year = {2011}
}
@article{Battiti1992,
annote = {doi: 10.1162/neco.1992.4.2.141},
author = {Battiti, Roberto},
doi = {10.1162/neco.1992.4.2.141},
file = {:Users/dennari/Documents/Papers/Battiti - 1992 - First- and Second-Order Methods for Learning Between Steepest Descent and {Newton}'s Method.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
month = mar,
number = {2},
pages = {141--166},
publisher = {{MIT} Press},
title = {First- and Second-Order Methods for Learning: Between Steepest Descent and {Newton}'s Method},
url = {http://dx.doi.org/10.1162/neco.1992.4.2.141},
volume = {4},
year = {1992}
}
@article{Minka1998,
author = {Minka, T},
file = {:Users/dennari/Documents/Papers/Minka - 1998 - Expectation-Maximization as lower bound maximization.pdf:pdf},
journal = {Tutorial published on the web at http://www-white.},
number = {1977},
pages = {1--8},
title = {Expectation-Maximization as lower bound maximization},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.29.8562\&amp;rep=rep1\&amp;type=pdf},
year = {1998}
}
@article{Paninski2010,
annote = {10.1007/s10827-009-0179-x},
author = {Paninski, Liam and Ahmadian, Yashar and Ferreira, Daniel and Koyama, Shinsuke and {Rahnama Rad}, Kamiar and Vidne, Michael and Vogelstein, Joshua and Wu, Wei},
file = {:Users/dennari/Documents/Papers/Paninski et al. - 2010 - A new look at state-space models for neural data.pdf:pdf},
issn = {0929-5313},
journal = {Journal of Computational Neuroscience},
number = {1},
pages = {107--126},
publisher = {Springer Netherlands},
title = {A new look at state-space models for neural data},
url = {http://dx.doi.org/10.1007/s10827-009-0179-x},
volume = {29},
year = {2010}
}
@article{Gordon1993,
author = {Gordon, N J and Salmond, D J and Smith, A F M},
file = {:Users/dennari/Documents/Papers/Gordon, Salmond, Smith - 1993 - Novel approach to nonlinearnon-{Gauss}ian {Bayes}ian state estimation.pdf:pdf},
isbn = {0956-375X VO - 140},
journal = {Radar and Signal Processing, IEE Proceedings F},
keywords = {{Bayes} methods,{Gauss}ian noise,{Kalman} filters,algorithm,bearings only tracking problem,bootstrap filter,extended {Kalman} filter,filtering and prediction theory,measurement model,non{Gauss}ian {Bayes}ian state estimation,nonlinear {Bayes}ian state estimation,random samples,recursive {Bayes}ian filters,simulation,state estimation,state transition model,state vector density,tracking},
number = {2},
pages = {107--113},
title = {Novel approach to nonlinear/non-{Gauss}ian {Bayes}ian state estimation},
volume = {140},
year = {1993}
}
@misc{Sarkka2012a,
address = {Espoo},
author = {S\"{a}rkk\"{a}, Simo},
file = {:Users/dennari/Documents/Papers/S\"{a}rkk\"{a} - 2012 - {Bayes}ian Estimation of Time-Varying Systems Discrete-Time Systems.pdf:pdf},
institution = {Aalto University School of Science},
organization = {Aalto University School of Science},
%number = {C},
title = {{Bayes}ian Estimation of Time-Varying Systems: Discrete-Time Systems},
%volume = {3},
year = {2012},
entrysubtype = {Lectures notes},
url = {http://becs.hut.fi/~ssarkka/course_k2012/full_course_booklet_2012.pdf},
urldate = {2012-08-20}
}
@article{shumway1982approach,
author = {Shumway, R H and Stoffer, D S},
file = {:Users/dennari/Documents/Papers/Shumway, Stoffer - 1982 - An approach to time series smoothing and forecasting using the {EM} algorithm.pdf:pdf},
journal = {Journal of time series analysis},
number = {4},
pages = {253--264},
publisher = {Wiley Online Library},
title = {An approach to time series smoothing and forecasting using the {EM} algorithm},
volume = {3},
year = {1982}
}
@book{Haykin2001,
author = {Haykin, Simon},
booktitle = {Communications},
file = {:Users/dennari/Documents/Papers/Haykin - 2001 - {Kalman} filtering and neural networks.pdf:pdf},
isbn = {0471221546},
publisher = {Wiley Online Library},
title = {{Kalman} filtering and neural networks},
url = {http://onlinelibrary.wiley.com/doi/10.1002/0471221546.fmatter\_indsub/summary},
year = {2001}
}
@techreport{Salakhutdinov2004,
author = {Salakhutdinov, Ruslan and Roweis, Sam and Ghahramani, Zoubin},
file = {:Users/dennari/Documents/Papers/Salakhutdinov, Roweis, Ghahramani - 2004 - Relationship between gradient and {EM} steps in latent variable models.pdf:pdf},
institution = {University of Toronto},
title = {Relationship between gradient and {EM} steps in latent variable models},
url = {http://www.cs.toronto.edu/~rsalakhu/papers/report.pdf},
urldate = {2012-07-19},
year = {2004}
}
@article{Sarkka2010,
author = {S\"{a}rkk\"{a}, Simo and Hartikainen, J},
doi = {10.1109/TAC.2010.2050017},
file = {:Users/dennari/Documents/Papers/S\"{a}rkk\"{a}, Hartikainen - 2010 - On {Gauss}ian Optimal Smoothing of Non-Linear State Space Models.pdf:pdf},
issn = {0018-9286},
journal = {Automatic Control, IEEE Transactions on},
keywords = {{Gauss}-Hermite quadrature,{Gauss}ian approximation,{Gauss}ian optimal smoothing,{Gauss}ian processes,Taylor series expansion,approximate optimal smoothing,approximation framework,approximation theory,fixed-lag optimal smoothing,fixed-point optimal smoothing,nonlinear fixed-interval optimal smoothing,nonlinear state space models,nonlinear stochastic state space models,smoothing methods,state-space methods,unscented transformation},
number = {8},
pages = {1938--1941},
title = {On {Gauss}ian Optimal Smoothing of Non-Linear State Space Models},
volume = {55},
year = {2010}
}
@article{Jia2012,
author = {Jia, Bin and Xin, Ming and Cheng, Yang},
doi = {10.1016/j.automatica.2011.08.057},
file = {:Users/dennari/Documents/Papers/Jia, Xin, Cheng - 2012 - Sparse-grid quadrature nonlinear filtering.pdf:pdf},
issn = {00051098},
journal = {Automatica},
month = feb,
number = {2},
pages = {327--341},
publisher = {Elsevier Ltd},
title = {Sparse-grid quadrature nonlinear filtering},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0005109811005541},
volume = {48},
year = {2012}
}
@article{Ito2000,
author = {Ito, Kazufumi},
file = {:Users/dennari/Documents/Papers/Ito - 2000 - {Gauss}ian filters for nonlinear filtering problems.pdf:pdf},
journal = {Automatic Control, IEEE Transactions on},
number = {5},
pages = {910--927},
title = {{Gauss}ian filters for nonlinear filtering problems},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=855552},
volume = {45},
year = {2000}
}
@article{Barbieri2006,
author = {Barbieri, R and Brown, E N},
doi = {10.1109/TBME.2005.859779},
isbn = {0018-9294 VO - 53},
journal = {Biomedical Engineering, IEEE Transactions on},
keywords = {Algorithms,Cardiovascular,Computer Simulation,Computer-Assisted,Data Interpretation,Diagnosis,Female,{Gauss}ian processes,Heart Failure,Heart Rate,Humans,Male,Models,Reproducibility of Results,Sensitivity and Specificity,Signal Processing,Statistical,adaptive filters,congestive heart failure,electrocardiography,heart rate variability,heartbeat dynamics,history dependent inverse {Gauss}ian mode,human heartbeat time series,medical signal processing,parameter estimation,point process adaptive filtering,sleep,time series,time-varying parameter estimation},
number = {1},
pages = {4--12},
title = {Analysis of heartbeat dynamics by point process adaptive filtering},
volume = {53},
year = {2006}
}
@book{Cappe2005,
author = {Capp\'{e}, Olivier and Moulines, Eric and Ryd\'{e}n, T.},
file = {:Users/dennari/Documents/Papers/Capp\'{e}, Moulines, Ryd\'{e}n - 2005 - Inference in hidden {Markov} models.pdf:pdf},
isbn = {9780387402642},
publisher = {Springer Verlag},
title = {Inference in hidden {Markov} models},
url = {http://books.google.com/books?hl=en\&amp;lr=\&amp;id=4d\_oEYn8Fl0C\&amp;oi=fnd\&amp;pg=PR5\&amp;dq=Inference+in+Hidden+{Markov}+Models\&amp;ots=tima6AR1qw\&amp;sig=nY0OHyJotdhsNdhPkJcCLsiFbGc},
year = {2005}
}
@phdthesis{Sarkka2006,
author = {S\"{a}rkk\"{a}, Simo},
file = {:Users/dennari/Documents/Papers/S\"{a}rkk\"{a} - 2006 - Recursive bayesian inference on stochastic differential equations.pdf:pdf},
isbn = {9512281279},
school = {Helsinki University of Technology},
title = {Recursive bayesian inference on stochastic differential equations},
year = {2006}
}
@book{pearl1988probabilistic,
author = {Pearl, J},
isbn = {9781558604797},
publisher = {Morgan Kaufmann Publishers},
series = {Morgan Kaufmann series in representation and reasoning},
title = {Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference},
url = {http://books.google.fi/books?id=AvNID7LyMusC},
year = {1988}
}
@misc{fminunc,
address = {Natick, MA, USA},
author = {{The Mathworks Inc.}},
title = {Optimization Toolbox User's Guide},
url = {http://www.mathworks.se/help/toolbox/optim},
urldate = {2012-07-25},
year = {2012}
}
@book{barber2011bayesian,
author = {Barber, David and Cemgil, A T and Chiappa, S},
booktitle = {{Bayes}ian Time Series Models},
isbn = {9780521196765},
pages = {1--31},
publisher = {Cambridge University Press},
title = {Inference and estimation in probabilistic time series models},
url = {http://books.google.fi/books?id=k4z6mOFsEv8C},
year = {2011}
}
@book{ljung1994modeling,
author = {Ljung, L and Glad, Torkel},
file = {:Users/dennari/Documents/Papers/Ljung, Glad - 1994 - Modeling of Dynamic Systems.pdf:pdf},
isbn = {9780135970973},
publisher = {PTR Prentice Hall},
series = {Prentice Hall Information and System Sciences Series},
title = {Modeling of Dynamic Systems},
url = {http://books.google.fi/books?id=zO9qQgAACAAJ},
year = {1994}
}
@incollection{Turner2011,
author = {Turner, Richard Eric and Sahani, Maneesh},
booktitle = {{Bayes}ian Time Series Models},
editor = {Barber, David and Cemgil, A T and Chiappa, Silvia},
file = {:Users/dennari/Documents/Papers/Turner, Sahani - 2011 - Two problems with variational expectation maximization for time series models.pdf:pdf},
isbn = {9780521196765},
pages = {104--124},
publisher = {Cambridge University Press},
title = {Two problems with variational expectation maximization for time series models},
year = {2011}
}
@article{Petersen2005,
abstract = {We analyze convergence of the expectation maximization ({EM}) and variational {Bayes} {EM} ({VBEM}) schemes for parameter estimation in noisy linear models. The analysis shows that both schemes are inefficient in the low-noise limit. The linear model with additive noise includes as special cases independent component analysis, probabilistic principal component analysis, factor analysis, and {Kalman} filtering. Hence, the results are relevant for many practical applications.},
author = {Petersen, Kaare Brandt and Winther, Ole and Hansen, Lars Kai},
file = {:Users/dennari/Documents/Papers/Petersen, Winther, Hansen - 2005 - On the slow convergence of {EM} and {VBEM} in low-noise linear models.pdf:pdf},
issn = {0899-7667},
journal = {Neural computation},
keywords = {Algorithms,Artifacts,{Bayes} Theorem,Factor Analysis, Statistical,Linear Models,Principal Component Analysis},
month = sep,
number = {9},
pages = {1921--1926},
pmid = {16106590},
title = {On the slow convergence of {EM} and {VBEM} in low-noise linear models.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/16106590},
volume = {17},
year = {2005}
}
@ARTICLE{Julier2000a, 
author={Julier, S. and Uhlmann, J. and Durrant-Whyte, H.F.}, 
journal={Automatic Control, IEEE Transactions on}, 
title={A new method for the nonlinear transformation of means and covariances in filters and estimators}, 
year={2000}, 
month={mar}, 
volume={45}, 
number={3}, 
pages={477--482}, 
keywords={ Kalman filter; covariance matrix; discrete time systems; error estimation; missile tracking; mobile robots; nonlinear filters; nonlinear systems; probability distribution; state estimation; covariance matrices; discrete time systems; error analysis; estimation theory; filtering theory; missile guidance; mobile robots; nonlinear systems; probability; state estimation;}, 
doi={10.1109/9.847726}, 
ISSN={0018-9286},}
@book{ljung1999system,
author = {Ljung, L},
file = {:Users/dennari/Documents/Papers/Ljung - 1999 - System Identification Theory for the User.pdf:pdf},
isbn = {9780136566953},
publisher = {Prentice Hall PTR},
series = {Prentice Hall Information And System Sciences Series},
title = {System Identification: Theory for the User},
url = {http://books.google.fi/books?id=nHFoQgAACAAJ},
year = {1999}
}
@article{BROYDEN01121973,
abstract = {This paper presents a local convergence analysis for several well-known quasi-{Newton} methods when used, without line searches, in an iteration of the formto solve for x* such that Fx* = 0. The basic idea behind the proofs is that under certain reasonable conditions on xo, F and xo, the errors in the sequence of approximations \{Hk\} to F′(x*)−1 can be shown to be of bounded deterioration in that these errors, while not ensured to decrease, can increase only in a controlled way. Despite the fact that Hk is not shown to approach F′(x*)−1, the methods considered, including those based on the single-rank Broyden and double-rank Davidon-Fletcher-Powell formulae, generate locally Q-superlinearly convergent sequences \{xk\}.},
author = {Broyden, C G and Dennis, J E and Mor\'{e}, Jorge J},
doi = {10.1093/imamat/12.3.223},
journal = {IMA Journal of Applied Mathematics},
number = {3},
pages = {223--245},
title = {On the Local and Superlinear Convergence of Quasi-{Newton} Methods},
url = {http://imamat.oxfordjournals.org/content/12/3/223.abstract},
volume = {12},
year = {1973}
}
@book{barber2012bayesian,
author = {Barber, David},
booktitle = {Machine Learning},
file = {:Users/dennari/Documents/Papers/Barber - 2012 - {Bayes}ian Reasoning and Machine Learning.pdf:pdf},
isbn = {9780521518147},
publisher = {Cambridge University Press},
title = {{Bayes}ian Reasoning and Machine Learning},
url = {http://books.google.fi/books?id=yxZtddB\_Ob0C},
year = {2012}
}
@book{durbin2012time,
author = {Durbin, J. and Koopman, S. J.},
file = {:Users/dennari/Documents/Papers/Durbin, Koopman - 2012 - Time Series Analysis by State Space Methods Second Edition.pdf:pdf},
isbn = {9780199641178},
publisher = {OUP Oxford},
series = {Oxford Statistical Science Series},
title = {Time Series Analysis by State Space Methods: Second Edition},
url = {http://books.google.fi/books?id=fOq39Zh0olQC},
year = {2012}
}
@book{jazwinski1970stochastic,
author = {Jazwinski, A H},
file = {:Users/dennari/Documents/Papers/Jazwinski - 1970 - Stochastic Processes and Filtering Theory.pdf:pdf},
isbn = {9780123815507},
number = {nid. 63},
publisher = {Academic Press},
series = {Mathematics in Science and Engineering},
title = {Stochastic Processes and Filtering Theory},
url = {http://books.google.fi/books?id=nGlSNvKyY2MC},
year = {1970}
}
@article{Gupta1974,
author = {Gupta, N. and Mehra, R.},
doi = {10.1109/TAC.1974.1100714},
file = {:Users/dennari/Documents/Papers/Gupta, Mehra - 1974 - Computational aspects of maximum likelihood estimation and reduction in sensitivity function calculations.pdf:pdf},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
month = dec,
number = {6},
pages = {774--783},
title = {Computational aspects of maximum likelihood estimation and reduction in sensitivity function calculations},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1100714},
volume = {19},
year = {1974}
}
@phdthesis{Merwe2004,
author = {Merwe, Rudolph Van Der},
file = {:Users/dennari/Documents/Papers/Merwe - 2004 - Sigma-point {Kalman} filters for probabilistic inference in dynamic state-space models.pdf:pdf},
number = {April},
school = {Oregon Health \& Science University},
title = {Sigma-point {Kalman} filters for probabilistic inference in dynamic state-space models},
%url = {http://speech.bme.ogi.edu/publications/ps/merwe04.pdf},
year = {2004}
}
@book{Doucet2001,
author = {Doucet, Arnaud and {De Freitas}, N and Gordon, N},
isbn = {9780387951461},
publisher = {Springer},
series = {Statistics for Engineering and Information Science},
title = {Sequential {Monte Carlo} Methods in Practice},
url = {http://books.google.fi/books?id=uxX-koqKtMMC},
year = {2001}
}
@article{Sarkka2012,
abstract = {In this article we introduce the DRIFTER algorithm, which is a new model based {Bayes}ian method for retrospective elimination of physiological noise from functional magnetic resonance imaging (fMRI) data. In the method, we first estimate the frequency trajectories of the physiological signals with the interacting multiple models (IMM) filter algorithm. The frequency trajectories can be estimated from external reference signals, or if the temporal resolution is high enough, from the fMRI data. The estimated frequency trajectories are then used in a state space model in combination of a {Kalman} filter (KF) and Rauch-Tung-Striebel (RTS) smoother, which separates the signal into an activation related cleaned signal, physiological noise, and white measurement noise components. Using experimental data, we show that the method outperforms the RETROICOR algorithm if the shape and amplitude of the physiological signals change over time.},
author = {S\"{a}rkk\"{a}, Simo and Solin, Arno and Nummenmaa, Aapo and Vehtari, Aki and Auranen, Toni and Vanni, Simo and Lin, Fa-Hsuan},
doi = {10.1016/j.neuroimage.2012.01.067},
file = {:Users/dennari/Documents/Papers/S\"{a}rkk\"{a} et al. - 2012 - Dynamic retrospective filtering of physiological noise in BOLD fMRI DRIFTER.pdf:pdf},
issn = {1095-9572},
journal = {NeuroImage},
keywords = {{Bayes}ian inference,Interacting multiple models,{Kalman} filter,Physiological noise,RTS smoother,functional magnetic resonance imaging},
month = jan,
number = {2},
pages = {1517--1527},
pmid = {22281675},
publisher = {Elsevier Inc.},
title = {Dynamic retrospective filtering of physiological noise in {BOLD} f{MRI}: {DRIFTER}.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/22281675},
volume = {60},
year = {2012}
}
@inproceedings{beal2003variational,
author = {Bernardo, JM and Bayarri, MJ and Berger, JO and Beal, M J and Ghahramani, Zoubin},
booktitle = {{Bayes}ian Statistics 7: Proceedings of the Seventh Valencia International Meeting},
file = {:Users/dennari/Documents/Papers/Bernardo et al. - 2003 - The variational {Bayes}ian {EM} algorithm for incomplete data with application to scoring graphical model structures.pdf:pdf},
keywords = {annealed importance sampling,bayes factors,graphical,latent variables,marginal likelihood,models,structure scoring,variational methods},
organization = {Oxford University Press},
pages = {453--464},
title = {The variational {Bayes}ian {EM} algorithm for incomplete data: with application to scoring graphical model structures},
url = {http://learning.eng.cam.ac.uk/zoubin/papers/valencia02.pdf},
volume = {7},
year = {2003}
}
@phdthesis{Murphy2002,
author = {Murphy, Kevin},
keywords = {ai ml,stat},
month = jul,
school = {UC Berkeley, Computer Science Division},
title = {Dynamic {Bayes}ian Networks},
subtitle = {Representation, Inference and Learning},
year = {2002}
}
@article{Sarkka2013,
note = {Advance online publication},
author = {S\"{a}rkk\"{a}, Simo and Sarmavuori, Juha},
doi = {http://dx.doi.org/10.1016/j.sigpro.2012.09.002},
file = {:Users/dennari/Documents/Papers/S\"{a}rkk\"{a}, Sarmavuori - 2013 - {Gauss}ian filtering and smoothing for continuous-discrete dynamic systems.pdf:pdf},
issn = {0165-1684},
journal = {Signal Processing},
keywords = {{Bayes}ian continuous-discrete filtering,{Bayes}ian continuous-discrete smoothing,{Gauss}ian approximation,{Kalman} filter,Rauch–Tung–Striebel smoother},
month = feb,
number = {2},
pages = {500--510},
title = {{Gauss}ian filtering and smoothing for continuous-discrete dynamic systems},
url = {http://www.sciencedirect.com/science/article/pii/S0165168412003210},
volume = {93},
year = {2013}
}
@article{Elliott1999,
author = {Elliott, R.J. and Krishnamurthy, Vikram},
file = {:Users/dennari/Documents/Papers/Elliott, Krishnamurthy - 1999 - New finite-dimensional filters for parameter estimation of discrete-time linear {Gauss}ian models.pdf:pdf},
journal = {Automatic Control, IEEE Transactions on},
number = {5},
pages = {938--951},
publisher = {IEEE},
title = {New finite-dimensional filters for parameter estimation of discrete-time linear {Gauss}ian models},
url = {http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=763210},
volume = {44},
year = {1999}
}
@misc{rucminf2012,
author = {Nielsen, H B and Mortensen, S. B.},
title = {Package ‘ucminf’},
entrysubtype = {Reference manual},
organization = {The Comprehensive R Archive Network},
url = {http://cran.r-project.org/web/packages/ucminf},
urldate = {2012-10-16},
year = {2012}
}
@article{Arasaratnam2009,
author = {Arasaratnam, Ienkaran and Haykin, Simon},
doi = {10.1109/TAC.2009.2019800},
file = {:Users/dennari/Documents/Papers/Arasaratnam, Haykin - 2009 - Cubature {Kalman} Filters.pdf:pdf},
issn = {0018-9286},
journal = {IEEE Transactions on Automatic Control},
keywords = {included},
mendeley-tags = {included},
month = jun,
number = {6},
pages = {1254--1269},
title = {Cubature {Kalman} Filters},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4982682},
volume = {54},
year = {2009}
}
@inproceedings{Salakhutdinov2003a,
address = {Washington DC},
author = {Salakhutdinov, Ruslan and Roweis, Sam and Ghahramani, Zoubin},
booktitle = {Proceedings of the Twentieth International Conference on Machine Learning},
file = {:Users/dennari/Documents/Papers/Salakhutdinov, Roweis, Ghahramani - 2003 - Optimization with {EM} and expectation-conjugate-gradient.pdf:pdf},
title = {Optimization with {EM} and expectation-conjugate-gradient},
url = {http://www.aaai.org/Papers/ICML/2003/ICML03-088.pdf},
year = {2003}
}
@book{Anderson1979,
author = {Anderson, B D O and Moore, J B},
file = {:Users/dennari/Documents/Papers/Anderson, Moore - 1979 - Optimal filtering.pdf:pdf},
isbn = {9780136381228},
publisher = {Prentice-Hall},
series = {Prentice-Hall information and system sciences series},
title = {Optimal filtering},
url = {http://books.google.fi/books?id=1o0oAQAAMAAJ},
year = {1979}
}
@article{Olsson2007,
author = {Olsson, Rasmus Kongsgaard and Petersen, Kaare Brandt and Lehn-Schi\o ler, Tue},
doi = {10.1162/neco.2007.19.4.1097},
file = {:Users/dennari/Documents/Papers/Olsson, Petersen, Lehn-Schi\o ler - 2007 - State-Space Models From the {EM} Algorithm to a Gradient Approach.pdf:pdf},
issn = {0899-7667},
journal = {Neural Computation},
month = apr,
number = {4},
pages = {1097--1111},
title = {State-Space Models: From the {EM} Algorithm to a Gradient Approach},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/neco.2007.19.4.1097},
volume = {19},
year = {2007}
}
@book{gelman2004,
author = {Gelman, A and Carlin, J B and Stern, H S and Rubin, D B},
isbn = {9781584883883},
publisher = {Chapman \& Hall/CRC},
title = {{Bayes}ian Data Analysis},
url = {http://books.google.fi/books?id=TNYhnkXQSjAC},
year = {2004}
}
@incollection{Wan2001,
author = {Wan, Eric A and Nelson, Alex T},
booktitle = {{Kalman} filtering and neural networks},
editor = {Haykin, Simon},
isbn = {0471221546},
pages = {123--170},
publisher = {Wiley Online Library},
title = {Dual Extended {Kalman} Filter Methods},
year = {2001}
}
@incollection{Neala1998,
author = {Neal, R.M. and Hinton, Geoffrey E.},
booktitle = {Learning in Graphical Models},
editor = {Jordan, M},
pages = {355--368},
publisher = {Mit Press},
title = {A View of the {EM} Algorithm that Justifies Incremental, Sparse and Other Variants},
year = {1998}
}
@article{Ratna2008,
author = {Ratna, Gopaluni,},
doi = {10.3182/20080706-5-KR-1001.01092},
editor = {Myung, Chung,},
file = {:Users/dennari/Documents/Papers/Ratna - 2008 - Identification of Nonlinear Processes with Known Model Structure under Missing Observations.pdf:pdf},
isbn = {9781123478},
month = jul,
pages = {6478--6483},
title = {Identification of Nonlinear Processes with Known Model Structure under Missing Observations},
url = {http://www.ifac-papersonline.net/Detailed/36802.html},
year = {2008}
}
@article{Kantas2009,
author = {Kantas, N and Doucet, Arnaud and Singh, SS},
file = {:Users/dennari/Documents/Papers/Kantas, Doucet, Singh - 2009 - An overview of sequential {Monte Carlo} methods for parameter estimation in general state-space models.pdf:pdf},
journal = {Proceedings of the IFAC},
keywords = {general state-space models,hidden markov models,parameter estimation,sequential monte carlo},
number = {Ml},
title = {An overview of sequential {Monte Carlo} methods for parameter estimation in general state-space models},
url = {http://ifly.nlr.nl/documents/P7.8 sysid09\_for\_iFly.pdf},
year = {2009}
}
@misc{Petersen2008,
abstract = {Matrix identities, relations and approximations. A desktop reference for quick overview of mathematics of matrices.},
annote = {Version 20081110},
author = {Petersen, K B and Pedersen, M S},
file = {:Users/dennari/Documents/Papers/Petersen, Pedersen - 2008 - The Matrix Cookbook.pdf:pdf},
keywords = {Matrix identity,inverse,matrix derivative,matrix relations},
month = oct,
publisher = {Technical University of Denmark},
title = {The Matrix Cookbook},
url = {http://www2.imm.dtu.dk/pubdb/p.php?3274},
urldate = {2012-10-20},
year = {2008}
}
@article{Sarkka2008a,
author = {S\"{a}rkk\"{a}, Simo},
doi = {10.1109/TAC.2008.919531},
file = {:Users/dennari/Documents/Papers/S\"{a}rkk\"{a} - 2008 - Unscented Rauch--Tung--Striebel Smoother.pdf:pdf},
isbn = {0018-9286 VO - 53},
journal = {Automatic Control, IEEE Transactions on},
keywords = {{Bayes} methods,{Kalman} filters,backward smoothing pass,fixed-interval unscented {Kalman} smoother,formal {Bayes}ian optimal smoothing equations,forward filtering,independent filters,nonlinear state-space models,smoothing methods,state-space methods,unscented Rauch-Tung-Striebel smoother,unscented transform},
number = {3},
pages = {845--849},
title = {Unscented {Rauch--Tung--Striebel} Smoother},
volume = {53},
year = {2008}
}
@techreport{Ghahramani1996,
author = {Ghahramani, Zoubin},
file = {:Users/dennari/Documents/Papers/Ghahramani - 1996 - Parameter estimation for linear dynamical systems.pdf:pdf},
institution = {University of Toronto},
number = {CRG-TR-96-2},
pages = {1--6},
title = {Parameter estimation for linear dynamical systems},
url = {mlg.eng.cam.ac.uk/zoubin/papers/tr-96-2.pdf},
year = {1996},
urldate = {2012-02-26}
}
@book{bar2004estimation,
author = {Bar-Shalom, Y and Li, X R and Kirubarajan, T},
file = {:Users/dennari/Documents/Papers/Bar-Shalom, Li, Kirubarajan - 2004 - Estimation with Applications to Tracking and Navigation Theory Algorithms and Software.pdf:pdf},
isbn = {9780471465218},
publisher = {John Wiley \& Sons},
title = {Estimation with Applications to Tracking and Navigation: Theory Algorithms and Software},
url = {http://books.google.fi/books?id=yTVw2jod9toC},
year = {2004}
}
@article{Ergun2007,
author = {Ergun, A and Barbieri, R and Eden, U T and Wilson, M A and Brown, E N},
doi = {10.1109/TBME.2006.888821},
isbn = {0018-9294 VO - 54},
journal = {Biomedical Engineering, IEEE Transactions on},
keywords = {Action Potentials,Algorithms,Animals,{Bayes} method,{Bayes} methods,Chapman-Kolmogorov system,Computer-Assisted,{Gauss}ian approximation,{Gauss}ian processes,Hippocampus,Models,{Monte Carlo} Method,{Monte Carlo} methods,Nerve Net,Neurological,Neuronal Plasticity,Rats,Signal Processing,Statistical,Stochastic Processes,adaptive filter algorithms,adaptive filters,approximation theory,bioelectric phenomena,brain,decoding,medical signal processing,neural receptive field plasticity,neural spiking activity,neural systems,neurophysiology,rat hippocampal neuron,sequential {Monte Carlo} methods,signal representation,state estimation,state transition probability density,steepest descent approximation,steepest descent point process filter,stochastic state point process filter},
number = {3},
pages = {419--428},
title = {Construction of Point Process Adaptive Filter Algorithms for Neural Systems Using Sequential {Monte Carlo} Methods},
volume = {54},
year = {2007}
}
@article{Kalman1960,
    Author = {Kalman, Rudolph Emil},
    Title = {A New Approach to Linear Filtering and Prediction Problems},
    Journal = {Transactions of the ASME--Journal of Basic Engineering},
    Volume = {82},
    Number = {Series D},
    Pages = {35--45},
    Year = {1960}
}
@article{Andrieu2010,
author = {Andrieu, Christophe and Doucet, Arnaud and Holenstein, Roman},
file = {:Users/dennari/Documents/Papers/Andrieu, Doucet, Holenstein - 2010 - Particle {{Markov}} chain {Monte Carlo} methods.pdf:pdf},
issn = {1467-9868},
journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
keywords = {{Bayes}ian inference,{Markov} chain {Monte Carlo} methods,Sequential {Monte Carlo} methods,State space models},
number = {3},
pages = {269--342},
publisher = {Blackwell Publishing Ltd},
title = {Particle {Markov} chain {Monte Carlo} methods},
url = {http://dx.doi.org/10.1111/j.1467-9868.2009.00736.x},
volume = {72},
year = {2010}
}
@article{Kushner1967,
author = {Kushner, H},
doi = {10.1109/TAC.1967.1098671},
file = {:Users/dennari/Documents/Papers/Kushner - 1967 - Approximations to optimal nonlinear filters.pdf:pdf},
isbn = {0018-9286 VO - 12},
journal = {Automatic Control, IEEE Transactions on},
keywords = {Nonlinear filtering,Optimal control},
number = {5},
pages = {546--556},
title = {Approximations to optimal nonlinear filters},
volume = {12},
year = {1967}
}
@article{Arasaratnam2011,
author = {Arasaratnam, Ienkaran and Haykin, Simon},
doi = {10.1016/j.automatica.2011.08.005},
file = {:Users/dennari/Documents/Papers/Arasaratnam, Haykin - 2011 - Cubature {Kalman} smoothers.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {cubature kalman filter,fixed-interval smoothing,rauch,striebel smoothing,tung},
month = aug,
number = {10},
pages = {2245--2250},
publisher = {Elsevier Ltd},
title = {Cubature {Kalman} smoothers},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0005109811003761},
volume = {47},
year = {2011}
}
@techreport{Nielsen2000,
author = {Nielsen, H B},
institution = {Department of Mathematical Modelling, Technical University of Denmark},
title = {UCMINF -- An Algorithm For Unconstrained, Nonlinear Optimization},
number = {IMM-REP-2000-19},
url = {http://www.imm.dtu.dk/~hbn/publ/TR0019.ps},
urldate = {2012-10-16},
year = {2000}
}
@article{Rauch1965,
author = {Rauch, H E and Tung, F and Striebel, C T},
doi = {10.2514/3.3166},
issn = {00011452},
journal = {AIAA Journal},
number = {8},
pages = {1445--1450},
title = {Maximum likelihood estimates of linear dynamic systems},
url = {http://doi.aiaa.org/10.2514/3.3166},
volume = {3},
year = {1965}
}
@article{Watson1983,
author = {Watson, MW},
file = {:Users/dennari/Documents/Papers/Watson - 1983 - Alternative Algorithms For The Estimation Of Dynamic Factor, Mimic And Varying Coefficient Regression Models.pdf:pdf},
journal = {Journal of Econometrics},
title = {Alternative Algorithms For The Estimation Of Dynamic Factor, Mimic And Varying Coefficient Regression Models},
url = {http://www.sciencedirect.com/science/article/pii/0304407683900660},
volume = {23},
year = {1983}
}
﻿@article{Mbalawata2011,
   author = {Mbalawata, Isambi and Särkkä, Simo and Haario, Heikki},
   affiliation = {Department of Mathematics and Physics, Lappeenranta University of Technology, P.O.Box 20, 53851 Lappeenranta, Finland},
   title = {Parameter estimation in stochastic differential equations with {Markov} chain {Monte Carlo} and non-linear {Kalman} filtering},
   journal = {Computational Statistics},
   publisher = {Physica Verlag, An Imprint of Springer-Verlag GmbH},
   issn = {0943-4062},
   keyword = {Mathematics and Statistics},
   pages = {1-29},
   url = {http://dx.doi.org/10.1007/s00180-012-0352-y},
   doi = {10.1007/s00180-012-0352-y},
   note= {Advance online publication},
   year = {2012}
}
@article{Olsson2006,
author = {Olsson, Rasmus Kongsgaard and Hansen, Lars Kai},
file = {:Users/dennari/Documents/Papers/Olsson, Hansen - 2006 - Linear State-Space Models for Blind Source Separation.pdf:pdf},
journal = {The Journal of Machine Learning Research},
keywords = {blind source separation,convo-,em,independent component analysis,lutive model,speech modelling,state-space model},
pages = {2585--2602},
publisher = {JMLR. org},
title = {Linear State-Space Models for Blind Source Separation},
volume = {7},
year = {2006}
}
@report{Petersen2005a,
author = {Petersen, Kaare Brandt and Winther, Ole},
file = {:Users/dennari/Documents/Papers/Petersen, Winther - 2005 - Explaining slow convergence of {EM} in low noise linear mixtures.pdf:pdf},
title = {Explaining slow convergence of {EM} in low noise linear mixtures},
institution = {Technical University of Denmark},
url = {http://orbit.dtu.dk/getResource?recordId=185954\&amp;objectId=1\&amp;versionId=1},
urldate = {2012-07-19},
year = {2005}
}
@inproceedings{julier1997new,
author = {Julier, Simon and Uhlmann, Jeffrey},
booktitle = {Int. Symp. Aerospace/Defense Sensing, Simul. and Controls},
file = {:Users/dennari/Documents/Papers/Julier, Uhlmann - 1997 - A new extension of the {Kalman} filter to nonlinear systems.pdf:pdf},
organization = {Spie Bellingham, WA},
pages = {26},
title = {A new extension of the {Kalman} filter to nonlinear systems},
volume = {3},
year = {1997}
}
@book{Grewal2008,
author = {Grewal, M S and Andrews, A P},
file = {:Users/dennari/Documents/Papers/Grewal, Andrews - 2008 - {Kalman} Filtering Theory and Practice Using {MATLAB}.pdf:pdf},
isbn = {9780470377802},
publisher = {Wiley},
title = {{Kalman} Filtering: Theory and Practice Using {MATLAB}},
url = {http://books.google.fi/books?id=J\_fqMHOCzB8C},
year = {2008}
}
@article{Koyama2010,
abstract = {A number of important data analysis problems in neuroscience can be solved using state-space models. In this article, we describe fast methods for computing the exact maximum a posteriori (MAP) path of the hidden state variable in these models, given spike train observations. If the state transition density is log-concave and the observation model satisfies certain standard assumptions, then the optimization problem is strictly concave and can be solved rapidly with {Newton}-Raphson methods, because the {Hess}ian of the loglikelihood is block tridiagonal. We can further exploit this block-tridiagonal structure to develop efficient parameter estimation methods for these models. We describe applications of this approach to neural decoding problems, with a focus on the classic integrate-and-fire model as a key example.},
author = {Koyama, Shinsuke and Paninski, Liam},
doi = {10.1007/s10827-009-0150-x},
file = {:Users/dennari/Documents/Papers/Koyama, Paninski - 2010 - Efficient computation of the maximum a posteriori path and parameter estimation in integrate-and-fire and more general state-space models.pdf:pdf},
issn = {1573-6873},
journal = {Journal of computational neuroscience},
keywords = {Action Potentials,Action Potentials: physiology,Algorithms,Animals,Computer Simulation,Models, Neurological,Models, Statistical,Neurons,Neurons: physiology},
month = aug,
number = {1-2},
pages = {89--105},
pmid = {19399603},
title = {Efficient computation of the maximum a posteriori path and parameter estimation in integrate-and-fire and more general state-space models.},
url = {http://www.ncbi.nlm.nih.gov/pubmed/19399603},
volume = {29},
year = {2010}
}
@book{harvey1991forecasting,
author = {Harvey, A C},
isbn = {9780521405737},
publisher = {Cambridge University Press},
title = {Forecasting, Structural Time Series Models and the {Kalman} Filter},
url = {http://books.google.fi/books?id=Kc6tnRHBwLcC},
year = {1991}
}
@article{Meng1997,
abstract = {Celebrating the 20th anniversary of the presentation of the paper by Dempster, Laird and Rubin which popularized the {EM} algorithm, we investigate, after a brief historical account, strategies that aim to make the {EM} algorithm converge faster while maintaining its simplicity and stability (e.g. automatic monotone convergence in likelihood). First we introduce the idea of a `working parameter' to facilitate the search for efficient data augmentation schemes and thus fast {EM} implementations. Second, summarizing various recent extensions of the {EM} algorithm, we formulate a general alternating expectation-conditional maximization algorithm AECM that couples flexible data augmentation schemes with model reduction schemes to achieve efficient computations. We illustrate these methods using multivariate t-models with known or unknown degrees of freedom and Poisson models for image reconstruction. We show, through both empirical and theoretical evidence, the potential for a dramatic reduction in computational time with little increase in human effort. We also discuss the intrinsic connection between {EM}-type algorithms and the Gibbs sampler, and the possibility of using the techniques presented here to speed up the latter. The main conclusion of the paper is that, with the help of statistical considerations, it is possible to construct algorithms that are simple, stable and fast.},
author = {Meng, Xiao-Li and van Dyk, David},
file = {:Users/dennari/Documents/Papers/Meng, Dyk - 1997 - The {EM} Algorithm--An Old Folk-Song Sung to a Fast New Tune.pdf:pdf},
issn = {00359246},
journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
number = {3},
pages = {pp. 511--567},
publisher = {Blackwell Publishing for the Royal Statistical Society},
title = {The {EM} Algorithm--An Old Folk-Song Sung to a Fast New Tune},
url = {http://www.jstor.org/stable/2346009},
volume = {59},
year = {1997}
}
@article{Harvey1990,
author = {Harvey, A C},
file = {:Users/dennari/Documents/Papers/Harvey - 1990 - Estimation procedures for structural time series models.pdf:pdf},
journal = {Journal of Forecasting},
number = {June 1988},
pages = {89--108},
title = {Estimation procedures for structural time series models},
url = {http://onlinelibrary.wiley.com/doi/10.1002/for.3980090203/abstract},
volume = {9},
year = {1990}
}
@INPROCEEDINGS{Goodwin2005, 
author={ Goodwin, G.C. and Aguero, J.C.}, 
booktitle={Decision and Control, 2005 and 2005 European Control Conference. CDC-ECC '05. 44th IEEE Conference on}, title={Approximate EM Algorithms for Parameter and State Estimation in Nonlinear Stochastic Models}, 
year={2005}, 
month={dec.}, 
volume={}, 
number={}, 
pages={ 368 - 373}, 
keywords={}, 
doi={10.1109/CDC.2005.1582183}, 
ISSN={},}
@incollection{Roweis2001,
author = {Roweis, Sam T and Ghahramani, Zoubin},
booktitle = {{Kalman} filtering and neural networks},
editor = {Haykin, Simon},
isbn = {0471221546},
pages = {175--216},
publisher = {Wiley Online Library},
title = {Learning Nonlinear Dynamical System Using the Expectation-Maximization Algorithm},
year = {2001}
}
@book{Mackay2004,
  title={Information Theory, Inference and Learning Algorithms},
  author={MacKay, D.J.C.},
  isbn={9780521642989},
  lccn={2003055133},
  url={http://books.google.fi/books?id=AKuMj4PN\_EMC},
  year={2003},
  publisher={Cambridge University Press}
}
@article{Gibson2005,
author = {Gibson, Stuart and Ninness, Brett},
doi = {10.1016/j.automatica.2005.05.008},
file = {:Users/dennari/Documents/Papers/Gibson, Ninness - 2005 - Robust maximum-likelihood estimation of multivariable dynamic systems.pdf:pdf},
issn = {00051098},
journal = {Automatica},
keywords = {parameter estimation,system identification},
month = oct,
number = {10},
pages = {1667--1682},
title = {Robust maximum-likelihood estimation of multivariable dynamic systems},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0005109805001810},
volume = {41},
year = {2005}
}
@article{Cappe2007,
author = {Capp\'{e}, Olivier and Godsill, Simon J. and Moulines, Eric},
doi = {10.1109/JPROC.2007.893250},
file = {:Users/dennari/Documents/Papers/Capp\'{e}, Godsill, Moulines - 2007 - An Overview of Existing Methods and Recent Advances in Sequential {Monte Carlo}.pdf:pdf},
issn = {0018-9219},
journal = {Proceedings of the IEEE},
month = may,
number = {5},
pages = {899--924},
title = {An Overview of Existing Methods and Recent Advances in Sequential {Monte Carlo}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=4266870},
volume = {95},
year = {2007}
}
@article{Godsill2007,
author = {Godsill, Simon J. and Vermaak, J and Ng, W and Li, J F},
doi = {10.1109/JPROC.2007.894708},
isbn = {0018-9219 VO - 95},
journal = {Proceedings of the IEEE},
keywords = {{Markov} processes,{Markov}ian process,aircraft,aircraft vehicle,clutter,dynamic model uncertainty,maneuvering object tracking,marine radar,marine vehicle,marine vehicles,moving object dynamics,particle filtering (numerical methods),radar clutter,radar tracking,random process,random processes,state-space model,target tracking,target trajectory representation,variable rate particle filtering algorithm},
number = {5},
pages = {925--952},
title = {Models and Algorithms for Tracking of Maneuvering Objects Using Variable Rate Particle Filters},
volume = {95},
year = {2007}
}
@book{luenberger2008,
author = {Luenberger, D G and Ye, Y},
edition = {3.},
file = {:Users/dennari/Documents/Papers/Luenberger, Ye - 2008 - Linear and Nonlinear Programming.pdf:pdf},
isbn = {9780387745022},
pages = {546},
publisher = {Springer},
series = {International Series in Operations Research \& Management Science},
title = {Linear and Nonlinear Programming},
url = {http://books.google.fi/books?id=-pD62uvi9lgC},
year = {2008}
}
